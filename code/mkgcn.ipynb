{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39266979-2eab-4877-a526-f4cd7b87c0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "import random\n",
    "import warnings\n",
    "import argparse\n",
    "import numpy as np\n",
    "from torch_geometric.nn import conv\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, auc, precision_recall_curve, average_precision_score\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from collections import defaultdict as ddict, Counter\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f546c85c-08db-4928-bdcc-9cd8382b471c",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser= argparse.ArgumentParser(description= 'Parser for Arguments')\n",
    "parser.add_argument('-seed', type= int, default= 0)\n",
    "parser.add_argument('-num_ent', type= int, default= 1209+ 172+ 154)\n",
    "parser.add_argument('-num_drug', type= int, default= 1209)\n",
    "parser.add_argument('-num_micr', type= int, default= 172)\n",
    "parser.add_argument('-num_dise', type= int, default= 154)\n",
    "# drug_micr_rel, 0; drug_dise_rel, 1; micr_dise_rel, 2; drug_inter_rel, 3; micr_inter_rel, 4; micr_drug_rel, 5; dise_drug_rel, 6; dies_micr_rel, 7.\n",
    "parser.add_argument('-drug_name_path', type= str, default= '../mdd/drug/drug_name.txt')\n",
    "parser.add_argument('-micr_name_path', type= str, default= '../mdd/microbe/microbe_name.txt')\n",
    "parser.add_argument('-dise_name_path', type= str, default= '../mdd/disease/disease_name.txt')\n",
    "parser.add_argument('-drug_micr_adj_path', type= str, default= '../mdd/adj/microbe_drug_adj.txt')\n",
    "parser.add_argument('-drug_struct_simi_path', type= str, default= '../mdd/drug/drug_struct_simi.txt')\n",
    "parser.add_argument('-drug_inter_adj_path', type= str, default= '../mdd/drug/drug_interact_adj.txt')\n",
    "parser.add_argument('-drug_fringer_simi_path', type= str, default= '../mdd/drug/drug_fringer_simi.txt')\n",
    "parser.add_argument('-drug_dise_adj_path', type= str, default= '../mdd/adj/drug_disease_adj.txt')\n",
    "parser.add_argument('-micr_ani_path', type= str, default= '../mdd/microbe/microbe_ani_simi.txt')\n",
    "parser.add_argument('-microbe_gene_simi_path', type= str, default= '../mdd/microbe/microbe_gene_simi.txt')\n",
    "parser.add_argument('-micr_inter_adj_path', type= str, default= '../mdd/microbe/microbe_interact_adj.txt')\n",
    "parser.add_argument('-micr_dise_adj_path', type= str, default= '../mdd/adj/microbe_disease_adj.txt')\n",
    "parser.add_argument('-dise_simi_path', type= str, default= '../mdd/disease/disease_dag_simi.txt')\n",
    "parser.add_argument('-train_ratio', type= float, default= 0.8)\n",
    "parser.add_argument('-valid_ratio', type= float, default= 0.1)\n",
    "parser.add_argument('-test_ratio', type= float, default= 0.1)\n",
    "parser.add_argument('-kg_file', type= str, default= 'kg_data/')\n",
    "parser.add_argument('-embed_dim', type= int, default= 128)\n",
    "parser.add_argument('-gcn_layer_num', type= int, default= 3)\n",
    "parser.add_argument('-layer1_hidden_units', type= int, default= 128)\n",
    "parser.add_argument('-layer2_hidden_units', type= int, default= 64)\n",
    "parser.add_argument('-layer3_hidden_units', type= int, default= 32)\n",
    "parser.add_argument('-epochs', type= int, default= 300)\n",
    "parser.add_argument('-patience', type= int, default= 6)\n",
    "parser.add_argument('-lr', type= float, default= 5e-3)\n",
    "parser.add_argument('-weight_decay', type= float, default= 1e-4)\n",
    "parser.add_argument('-lambda1', type= float, default= 2** (-3))\n",
    "parser.add_argument('-lambda2', type= float, default= 2** (-4))\n",
    "parser.add_argument('-h1_gamma', type= float, default= 2 ** (-5))\n",
    "parser.add_argument('-h2_gamma', type= float, default= 2 ** (-3))\n",
    "parser.add_argument('-h3_gamma', type= float, default= 2 ** (-3))\n",
    "parser.add_argument('-threshold', type= float, default= 0.8)\n",
    "parser.add_argument('-device', type= str, default= 'cpu')\n",
    "parser.add_argument('-pt_file', type= str, default= 'checkpoint/')\n",
    "parser.add_argument('-memo_file4mkgcn', type= str, default= 'memo/mkgcn.txt')\n",
    "parser.add_argument('-pt_file_name', type= str, default= 'mkgcn.pt')\n",
    "parser.add_argument('-test_result_file', type= str, default= 'result/mkgcn_test_result.txt')\n",
    "params= parser.parse_args([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f47604-e897-47b5-a51c-b3544d31d312",
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataloader(object):\n",
    "    def __init__(self, params):\n",
    "        super().__init__()\n",
    "        self.params= params\n",
    "        self.drug_micr_asso_mat, self.drug_dise_asso_mat, self.drug_inter_mat, self.drug_struct_simi_mat, self.drug_fringer_simi_mat= self.load_drug_data()\n",
    "        self.train_xy, self.valid_xy, self.test_xy= self.split_dataset()\n",
    "        self.drug_micr_asso_mat_zy= self.get_asso_mat_zy()\n",
    "        self.micr_ani_mat, self.micr_inter_mat, self.micr_dise_asso_mat, self.micr_asso_simi_mat, self.micr_gene_simi_mat= self.load_micr_data()\n",
    "        self.dise_simi_mat, self.drug_dise_drug_simi_mat, self.micr_dise_micr_simi_mat= self.load_dise_data()\n",
    "        self.micr_inte_simi_mat= torch.where(self.micr_ani_mat> 0, self.micr_ani_mat, self.micr_gene_simi_mat)\n",
    "        self.hete_graph_mat= torch.cat([torch.cat([self.drug_struct_simi_mat, self.drug_micr_asso_mat_zy], dim= 1),\\\n",
    "                                    torch.cat([self.drug_micr_asso_mat_zy.T, self.micr_asso_simi_mat], dim= 1)], dim= 0).float()\n",
    "        self.hete_graph_idx= torch.nonzero(self.hete_graph_mat>= self.params.threshold).to(torch.long)\n",
    "        self.fea= torch.cat((torch.cat((torch.zeros((self.params.num_drug, self.params.num_drug)), self.drug_micr_asso_mat_zy), dim= 1), torch.cat((self.drug_micr_asso_mat_zy.T, torch.zeros((self.params.num_micr, self.params.num_micr))), dim= 1)), dim= 0)\n",
    "        self.introduce()\n",
    "\n",
    "    # @introduce data\n",
    "    def introduce(self):\n",
    "        print(f'Drug microbe association num: {self.drug_micr_asso_mat.sum()}\\nDrug interaction num: {self.drug_inter_mat.sum()}\\nMicrobe interaction num: {self.micr_inter_mat.sum()}')\n",
    "        print(f'Drug disease association num: {self.drug_dise_asso_mat.sum()}\\nMicrobe disease association num: {self.micr_dise_asso_mat.sum()}')\n",
    "\n",
    "    # @ mask\n",
    "    def get_asso_mat_zy(self):\n",
    "        asso_mat_zy= self.drug_micr_asso_mat.clone()\n",
    "        asso_mat_zy[self.valid_xy[:, 0], self.valid_xy[:, 1]]= 0\n",
    "        asso_mat_zy[self.test_xy[:, 0], self.test_xy[:, 1]]= 0\n",
    "        return asso_mat_zy\n",
    "    \n",
    "    # @create knowledge graph data\n",
    "    def create_kg_data(self):\n",
    "        if os.path.exists(self.params.kg_file)== False:os.makedirs(self.params.kg_file)\n",
    "        # drug microbe association data\n",
    "        drug_micr_train, drug_micr_valid, drug_micr_test= self.train_xy[self.drug_micr_asso_mat[self.train_xy[:, 0], self.train_xy[:, 1]]== 1],\\\n",
    "        self.valid_xy[self.drug_micr_asso_mat[self.valid_xy[:, 0], self.valid_xy[:, 1]]== 1],\\\n",
    "        self.test_xy[self.drug_micr_asso_mat[self.test_xy[:, 0], self.test_xy[:, 1]]== 1]\n",
    "        # drug disease association data\n",
    "        drug_dise_train, micr_dise_train, drug_inter_train, micr_inter_train= self.drug_dise_asso_mat.nonzero(), self.micr_dise_asso_mat.nonzero(), self.drug_inter_mat.nonzero(), self.micr_inter_mat.nonzero()\n",
    "        # add offset\n",
    "        drug_micr_valid+= torch.tensor([0, self.params.num_drug]); drug_micr_test+= torch.tensor([0, self.params.num_drug]); drug_micr_train+= torch.tensor([0, self.params.num_drug])\n",
    "        drug_dise_train+= torch.tensor([0, self.params.num_drug+ self.params.num_micr]); micr_dise_train+= torch.tensor([self.params.num_drug, self.params.num_drug+ self.params.num_micr]); micr_inter_train+= torch.tensor([self.params.num_drug, self.params.num_drug])\n",
    "        # add rel\n",
    "        drug_micr_train, drug_micr_valid, drug_micr_test= drug_micr_train[:, [0, 1, 1]], drug_micr_valid[:, [0, 1, 1]], drug_micr_test[:, [0, 1, 1]]\n",
    "        drug_dise_train, micr_dise_train, drug_inter_train, micr_inter_train= drug_dise_train[:, [0, 1, 1]], micr_dise_train[:, [0, 1, 1]], drug_inter_train[:, [0, 1, 1]], micr_inter_train[:, [0, 1, 1]]\n",
    "        drug_micr_train[:, 2], drug_micr_valid[:, 2], drug_micr_test[:, 2], drug_dise_train[:, 2], micr_dise_train[:, 2], drug_inter_train[:, 2], micr_inter_train[:, 2]= 0, 0, 0, 1, 2, 3, 4\n",
    "        # savefile\n",
    "        train= torch.cat([drug_micr_train, drug_dise_train, micr_dise_train, drug_inter_train, micr_inter_train], dim= 0)\n",
    "        val= drug_micr_valid\n",
    "        test= drug_micr_test\n",
    "        np.savetxt(f'{params.kg_file}//train.txt', train, fmt= '%d', delimiter= '\\t', encoding= 'utf-8-sig')\n",
    "        np.savetxt(f'{params.kg_file}//valid.txt', val, fmt= '%d', delimiter= '\\t', encoding= 'utf-8-sig')\n",
    "        np.savetxt(f'{params.kg_file}//test.txt', test, fmt= '%d', delimiter= '\\t', encoding= 'utf-8-sig')\n",
    "        print(f'Knowledge graph data has prepared...')\n",
    "\n",
    "    # @split data set\n",
    "    def split_dataset(self):\n",
    "        train_xy, valid_xy, test_xy= [], [], []\n",
    "        for i in range(self.params.num_drug):\n",
    "            first= True\n",
    "            for j in range(self.params.num_micr):\n",
    "                if self.drug_micr_asso_mat[i, j]== 1 and first:\n",
    "                    train_xy.append([i, j])\n",
    "                    first= False\n",
    "                else:\n",
    "                    num= torch.rand(1)\n",
    "                    if num< self.params.train_ratio:\n",
    "                        train_xy.append([i, j])\n",
    "                    elif num>= self.params.train_ratio and num< self.params.train_ratio+ self.params.valid_ratio:\n",
    "                        valid_xy.append([i, j])\n",
    "                    else:\n",
    "                        test_xy.append([i, j])        \n",
    "        print(f'Spliting data has finished...')\n",
    "        return torch.tensor(train_xy), torch.tensor(valid_xy), torch.tensor(test_xy)\n",
    "\n",
    "    # @load disease data\n",
    "    def load_dise_data(self):\n",
    "        dise_simi_mat= torch.from_numpy(np.loadtxt(self.params.dise_simi_path, encoding= 'utf-8-sig'))\n",
    "        drug_dise_drug_simi_mat, micr_dise_micr_simi_mat= torch.matmul(nn.functional.normalize(self.drug_inter_mat, p= 2, dim= 1), nn.functional.normalize(self.drug_inter_mat, p= 2, dim= 1).T),\\\n",
    "        torch.matmul(nn.functional.normalize(self.micr_inter_mat, p= 2, dim= 1), nn.functional.normalize(self.micr_inter_mat, p= 2, dim= 1).T)\n",
    "        for i in range(self.params.num_drug): drug_dise_drug_simi_mat[i, i]= 1.0\n",
    "        for i in range(self.params.num_micr): micr_dise_micr_simi_mat[i, i]= 1.0\n",
    "        return dise_simi_mat, drug_dise_drug_simi_mat, micr_dise_micr_simi_mat\n",
    "\n",
    "    # @load micr data\n",
    "    def load_micr_data(self):\n",
    "        micr_ani_mat= torch.from_numpy(np.loadtxt(self.params.micr_ani_path, encoding= 'utf-8-sig'))\n",
    "        micr_gene_simi_mat= (torch.from_numpy(np.loadtxt(self.params.microbe_gene_simi_path, encoding= 'utf-8-sig'))+ 1)/ 2\n",
    "        micr_inter_mat= self.load_adj_data(self.params.micr_inter_adj_path, sp= (self.params.num_micr, self.params.num_micr))\n",
    "        micr_dise_mat= self.load_adj_data(self.params.micr_dise_adj_path, sp= (self.params.num_micr, self.params.num_dise))\n",
    "        micr_asso_simi_mat= torch.matmul(nn.functional.normalize(self.drug_micr_asso_mat_zy.T, p= 2, dim= 1), nn.functional.normalize(self.drug_micr_asso_mat_zy.T, p= 2, dim= 1).T)\n",
    "        for i in range(self.params.num_micr):micr_asso_simi_mat[i, i]= 1\n",
    "        for i in range(self.params.num_micr):micr_ani_mat[i, i]= 1\n",
    "        return micr_ani_mat, micr_inter_mat, micr_dise_mat, micr_asso_simi_mat, micr_gene_simi_mat\n",
    "\n",
    "    # @load drug data\n",
    "    def load_drug_data(self):\n",
    "        drug_dise_asso_mat= self.load_adj_data(self.params.drug_dise_adj_path, sp= (self.params.num_drug, self.params.num_dise))\n",
    "        drug_micr_asso_mat= self.load_adj_data(self.params.drug_micr_adj_path, sp= (self.params.num_drug, self.params.num_micr))\n",
    "        drug_inter_mat= self.load_adj_data(self.params.drug_inter_adj_path, sp= (self.params.num_drug, self.params.num_drug))\n",
    "        drug_struct_simi_mat= torch.from_numpy(np.loadtxt(self.params.drug_struct_simi_path, encoding= 'utf-8-sig'))\n",
    "        drug_fringer_simi_mat= torch.from_numpy(np.loadtxt(self.params.drug_fringer_simi_path, encoding= 'utf-8-sig'))\n",
    "        return drug_micr_asso_mat, drug_dise_asso_mat, drug_inter_mat, drug_struct_simi_mat, drug_fringer_simi_mat\n",
    "    \n",
    "    # @load adj data\n",
    "    def load_adj_data(self, path, sp= (1209, 172)):\n",
    "        idx= torch.from_numpy(np.loadtxt(path, encoding= 'utf-8-sig')).long()- 1\n",
    "        mat= torch.zeros((sp[0], sp[1]))\n",
    "        mat[idx[:, 0], idx[:, 1]]= 1\n",
    "        return mat\n",
    "    \n",
    "    # @NRWR, neighborhood random walk with restart\n",
    "    def random_walk_root(self, A, alpha, epoch, nei, eps, err):\n",
    "        Mask_mat= (torch.matrix_power(A, nei)- torch.matrix_power(A, nei- 1))> 0\n",
    "        W= nn.functional.normalize(A, p= 1, dim= 1)\n",
    "        S_last= torch.eye(A.shape[0])\n",
    "        for i in range(epoch):\n",
    "            S_new= alpha* torch.matmul(S_last, W)+ (1- alpha)* torch.eye(A.shape[0])\n",
    "            S_new= nn.functional.normalize(Mask_mat* S_new, p= 1, dim= 1)\n",
    "            if (S_new- S_last).abs().sum()<= err* A.shape[0]** 2:\n",
    "                print('converge...');break\n",
    "            S_last= S_new\n",
    "        return S_new\n",
    "\n",
    "    # write into memo\n",
    "    def write2memo(self, mr, mrr, hits10):\n",
    "        with open(f'{self.params.memo_file4kg}', 'a+') as f:\n",
    "            f.write(f'{self.params.lr_kg}\\t{self.params.weight_decay_kg}\\t{mr}\\t{mrr}\\t{hits10}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2813f56-244f-4408-aa97-ffc2fc28b371",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loss4MKGCN(nn.Module):\n",
    "\tdef __init__(self, args):\n",
    "\t\tsuper().__init__()\n",
    "\t\tself.lambda1, self.lambda2= args.lambda1, args.lambda2\n",
    "\t\t# alpha1, (1373, 173); alpha2, (173, 1373);\n",
    "\tdef forward(self, labels, preds, lnc_lap, dis_lap, alpha1, alpha2):\n",
    "\t\t# mse\n",
    "\t\tbatch_loss= ((preds- labels)** 2).sum()\n",
    "\t\t# reg loss\n",
    "\t\tlnc_reg= torch.trace(torch.matmul(torch.matmul(alpha1.T, lnc_lap), alpha1))\n",
    "\t\tdis_reg= torch.trace(torch.matmul(torch.matmul(alpha2.T, dis_lap), alpha2))\n",
    "\t\treg= (self.lambda1* lnc_reg+ self.lambda2* dis_reg).sum()\n",
    "\t\t# total\n",
    "\t\tloss= batch_loss+ reg\n",
    "\t\treturn loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bff7079-4b0a-4f43-aa96-6d4c40c5fae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalized_embedding(embeddings):\n",
    "    [row, col] = embeddings.size()\n",
    "    ne = torch.zeros([row, col])\n",
    "    for i in range(row):\n",
    "        ne[i, :] = (embeddings[i, :] - min(embeddings[i, :])+ 1e-15) / (max(embeddings[i, :]) - min(embeddings[i, :])+ 1e-15)\n",
    "    return ne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5325617-9f5c-426f-b7c1-dd03c1abc004",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getGipKernel(y, trans, gamma, normalized=False):\n",
    "    if trans:y = y.T\n",
    "    if normalized:y = normalized_embedding(y)\n",
    "    krnl = torch.mm(y, y.T)\n",
    "    krnl = krnl / torch.mean(torch.diag(krnl))\n",
    "    krnl = torch.exp(-kernelToDistance(krnl) * gamma)\n",
    "    return krnl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5dcab6e-e8dd-4596-9d53-49366da295e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalized_kernel(K):\n",
    "    K = abs(K)\n",
    "    k = K.flatten().sort()[0]\n",
    "    min_v = k[torch.nonzero(k, as_tuple=False)[0]]\n",
    "    K[torch.where(K == 0)] = min_v\n",
    "    D = torch.diag(K)\n",
    "    D = D.sqrt()\n",
    "    S = K / (D * D.T)\n",
    "    return S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a5eabf-5656-4e4f-b2a9-fc3393de7f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kernelToDistance(k):\n",
    "    di = torch.diag(k).T\n",
    "    d = di.repeat(len(k)).reshape(len(k), len(k)).T + di.repeat(len(k)).reshape(len(k), len(k)) - 2 * k\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c655dacb-956f-4e1e-a2d4-1f628022b6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def laplacian(kernel):\n",
    "    # 按列求和\n",
    "    d1 = sum(kernel)\n",
    "    # 得到对角矩阵\n",
    "    D_1 = torch.diag(d1)\n",
    "    # 拉普拉斯矩阵\n",
    "    L_D_1 = D_1 - kernel\n",
    "    # 度矩阵进行标准化\n",
    "    D_5 = D_1.rsqrt()\n",
    "    # 条件\n",
    "    D_5 = torch.where(torch.isinf(D_5), torch.full_like(D_5, 0), D_5)\n",
    "    # 对核进行标准化\n",
    "    L_D_11 = torch.mm(D_5, L_D_1)\n",
    "    L_D_11 = torch.mm(L_D_11, D_5)\n",
    "    return L_D_11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7482b5-266f-4aab-a1d0-5bdbcb79a091",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MKGCN(nn.Module):\n",
    "    # 参数对象; 药物相似性; 微生物相似性; 遮掩的关联矩阵; 特征矩阵;\n",
    "    def __init__(self, params, drug_sim, micr_sim, hete_ass_idx, hete_ass_weight, fea):\n",
    "        super().__init__()\n",
    "        self.params= params\n",
    "        self.drug_nums, self.micro_nums= params.num_drug, params.num_micr\n",
    "        self.gcn1_units, self.gcn2_units, self.gcn3_units= self.params.layer1_hidden_units, self.params.layer2_hidden_units, self.params.layer3_hidden_units\n",
    "        self.lambda1, self.lambda2, self.h1_gamma, self.h2_gamma, self.h3_gamma= self.params.lambda1, self.params.lambda2, self.params.h1_gamma, self.params.h2_gamma, self.params.h3_gamma\n",
    "        self.kernel_size= self.params.gcn_layer_num+ 1\n",
    "        self.drug_sim, self.micro_sim= drug_sim, micr_sim\n",
    "        self.drug_kernel_weights= torch.ones(self.kernel_size)/ self.kernel_size\n",
    "        self.micro_kernel_weights= torch.ones(self.kernel_size)/ self.kernel_size\n",
    "        self.gcn1, self.gcn2, self.gcn3= conv.GCNConv(self.micro_nums+ self.drug_nums, self.gcn1_units), conv.GCNConv(self.gcn1_units, self.gcn2_units), conv.GCNConv(self.gcn2_units, self.gcn3_units)\n",
    "        self.alpha1, self.alpha2= torch.randn(self.drug_nums, self.micro_nums), torch.randn(self.micro_nums, self.drug_nums)\n",
    "        self.relu= nn.ReLU()\n",
    "        self.hete_ass_idx= hete_ass_idx\n",
    "        self.hete_ass_weight= hete_ass_weight\n",
    "        self.fea= fea\n",
    "        self.lap_drug_kernel, self.lap_micro_kernel= [], []\n",
    "        self.kernel4drug, self.kernel4micro= torch.zeros((self.drug_nums, self.drug_nums)), torch.zeros((self.micro_nums, self.micro_nums))\n",
    "\n",
    "    # X, 特征矩阵; ass_mat, 遮掩之后的关联矩阵; \n",
    "    def forward(self, left, right):\n",
    "        # gcn1, emb1, (1546, 128);\n",
    "        emb1= self.relu(self.gcn1(self.fea, self.hete_ass_idx.T, self.hete_ass_weight))\n",
    "        self.kernel4drug= self.drug_kernel_weights[0]* getGipKernel(emb1[0: self.drug_nums], 0, self.h1_gamma, True)\n",
    "        self.kernel4micro= self.micro_kernel_weights[0]* getGipKernel(emb1[self.drug_nums: ], 0, self.h1_gamma, True)\n",
    "        emb2= self.relu(self.gcn2(emb1, self.hete_ass_idx.T, self.hete_ass_weight))\n",
    "        self.kernel4drug+= self.drug_kernel_weights[1]* getGipKernel(emb2[0: self.drug_nums], 0, self.h2_gamma, True)\n",
    "        self.kernel4micro+= self.micro_kernel_weights[1]* getGipKernel(emb2[self.drug_nums: ], 0, self.h2_gamma, True)\n",
    "        emb3= self.relu(self.gcn3(emb2, self.hete_ass_idx.T, self.hete_ass_weight))\n",
    "        self.kernel4drug+= self.drug_kernel_weights[2]* getGipKernel(emb3[0: self.drug_nums], 0, self.h3_gamma, True)\n",
    "        self.kernel4micro+= self.micro_kernel_weights[2]* getGipKernel(emb3[self.drug_nums: ], 0, self.h3_gamma, True)\n",
    "        # create drug& micro kernel\n",
    "        self.kernel4drug+= self.drug_kernel_weights[3]* self.drug_sim\n",
    "        self.kernel4micro+= self.micro_kernel_weights[3]* self.micro_sim\n",
    "        # 对药物混合核进行标准化\n",
    "        self.kernel4drug, self.kernel4micro= normalized_kernel(self.kernel4drug), normalized_kernel(self.kernel4micro)\n",
    "        # 对药物核\\微生物核进行标准化\n",
    "        self.lap_drug_kernel, self.lap_micro_kernel= laplacian(self.kernel4drug), laplacian(self.kernel4micro)\n",
    "        # 获取结果矩阵\n",
    "        out= (torch.matmul(self.kernel4drug, self.alpha1)+ torch.matmul(self.alpha2.T, self.kernel4micro))/ 2\n",
    "        # return\n",
    "        return out[left, right]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2fe75fa-378a-4823-a0a1-726020065d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_auc_aupr_cpt(test_xy, test_label, pred, ass_mat_shape):\n",
    "    label_mat, pred_mat= torch.zeros((ass_mat_shape)) -1, torch.zeros((ass_mat_shape)) -1\n",
    "    label_mat[test_xy[:, 0], test_xy[:, 1]], pred_mat[test_xy[:, 0], test_xy[:, 1]]= test_label* 1.0, pred\n",
    "    bool_mat4mark_test_examp= (label_mat!= -1)\n",
    "    aucs, auprs= [], []\n",
    "    for i in range(ass_mat_shape[0]):\n",
    "        test_examp_loc= bool_mat4mark_test_examp[i]\n",
    "        pos_num= label_mat[i, test_examp_loc].sum()\n",
    "        if pos_num> 0 and (test_examp_loc).sum()- pos_num> 0:\n",
    "            fpr4rowi, tpr4rowi, _= roc_curve(label_mat[i, test_examp_loc], pred_mat[i, test_examp_loc])\n",
    "            prec4rowi, recall4rowi, _= precision_recall_curve(label_mat[i, test_examp_loc], pred_mat[i, test_examp_loc])\n",
    "            prec4rowi[-1]= [1, 0][(int)(prec4rowi[-2]== 0)]\n",
    "            aucs.append(auc(fpr4rowi, tpr4rowi));auprs.append(auc(recall4rowi, prec4rowi))\n",
    "    return np.mean(aucs), np.mean(auprs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56f17c1-a9fc-45e0-8a31-343850ac67d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "\t\"\"\"docstring for EarlyStopping\"\"\"\n",
    "\tdef __init__(self, patience, pt_file= 'checkpoint/', file_name= 'checkpoint.pt', mess_out= True, eps= 0):\n",
    "\t\tsuper().__init__()\n",
    "\t\tself.patience, self.eps, self.pt_file, self.file_name, self.mess_out= patience, eps, pt_file, file_name, mess_out\n",
    "\t\tself.best_score, self.counter, self.flag= None, 0, False\n",
    "\t\tif os.path.exists(self.pt_file)== False:os.makedirs(self.pt_file)\n",
    "\t\n",
    "\tdef __call__(self, val_loss, model):\n",
    "\t\tscore= -val_loss\n",
    "\t\tif self.best_score is None:\n",
    "\t\t\tself.best_score= score\n",
    "\t\t\tself.save_checkpoint(model)\n",
    "\t\telif score<= self.best_score- self.eps:\n",
    "\t\t\tself.counter+= 1\n",
    "\t\t\tif self.mess_out:print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "\t\t\tif self.counter>= self.patience:\n",
    "\t\t\t\tself.flag= True\n",
    "\t\telse:\n",
    "\t\t\tself.best_score= score\n",
    "\t\t\tself.save_checkpoint(model)\n",
    "\t\t\tself.counter= 0\n",
    "\n",
    "\tdef save_checkpoint(self, model):\n",
    "\t\ttorch.save(model, f'{self.pt_file}//{self.file_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ffb8d6f-10bd-4765-8a43-a52aac1e17f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(params.seed)\n",
    "np.random.seed(params.seed)\n",
    "torch.manual_seed(params.seed)\n",
    "torch.cuda.manual_seed(params.seed)\n",
    "torch.cuda.manual_seed_all(params.seed)\n",
    "os.environ['PYTHONHASHSEED'] = str(params.seed)    \n",
    "torch.backends.cudnn.deterministic = True\n",
    "dl= dataloader(params)\n",
    "hete_graph_weight= dl.hete_graph_mat[dl.hete_graph_idx[:, 0], dl.hete_graph_idx[:, 1]].clone()\n",
    "train_xy, valid_xy, test_xy= dl.train_xy.clone(),  dl.valid_xy.clone(),  dl.test_xy.clone()\n",
    "train_label, valid_label, test_label= dl.drug_micr_asso_mat[train_xy[:, 0], train_xy[:, 1]], dl.drug_micr_asso_mat[valid_xy[:, 0], valid_xy[:, 1]], dl.drug_micr_asso_mat[test_xy[:, 0], test_xy[:, 1]]\n",
    "net, reg_mse= MKGCN(params, dl.drug_struct_simi_mat.clone(), dl.micr_asso_simi_mat.clone(), dl.hete_graph_idx.clone(), hete_graph_weight.clone(), dl.fea.clone()).to(params.device), Loss4MKGCN(params).to(params.device)\n",
    "optimizer= torch.optim.Adam(net.parameters(), lr= params.lr, weight_decay= params.weight_decay)\n",
    "earlystopping= EarlyStopping(patience= params.patience, pt_file= params.pt_file, file_name= params.pt_file_name, mess_out= True)\n",
    "pred= []\n",
    "for ep in range(params.epochs):\n",
    "    net.train()\n",
    "    time_start= time.time()\n",
    "    logp= net(train_xy[:, 0], train_xy[:, 1])\n",
    "    loss= reg_mse(train_label, logp, net.lap_drug_kernel, net.lap_micro_kernel, net.alpha1, net.alpha2)\n",
    "    net.alpha1 = torch.matmul(\\\n",
    "        torch.matmul((torch.matmul(net.kernel4drug, net.kernel4drug) + net.lambda1 * net.lap_drug_kernel).inverse(), net.kernel4drug),\\\n",
    "        2 * dl.drug_micr_asso_mat_zy - torch.matmul(net.alpha2.T, net.kernel4micro.T)).detach()\n",
    "    net.alpha2 = torch.mm(torch.mm((torch.mm(net.kernel4micro, net.kernel4micro) + net.lambda2 * net.lap_micro_kernel).inverse(), net.kernel4micro),\\\n",
    "        2 * dl.drug_micr_asso_mat_zy.T - torch.mm(net.alpha1.T, net.kernel4drug.T)).detach()\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    time_end= time.time()\n",
    "    print(f'epoch: {ep+ 1}, train loss: {loss}, time: {time_end- time_start}')\n",
    "    # valid\n",
    "    net.eval(); val_loss= 0; pred= []\n",
    "    with torch.no_grad():\n",
    "        logp= net(valid_xy[:, 0], valid_xy[:, 1])\n",
    "        val_loss= reg_mse(valid_label, logp, net.lap_drug_kernel, net.lap_micro_kernel, net.alpha1, net.alpha2).item()\n",
    "        pred.append(logp)\n",
    "    pred= torch.cat(pred).cpu()\n",
    "    roc_auc, aupr_auc= avg_auc_aupr_cpt(dl.valid_xy, valid_label, pred, (1209, 172))\n",
    "    print(f'epoch: {ep+ 1}, valid loss: {val_loss}, auc: {roc_auc}, aupr: {aupr_auc}')\n",
    "    earlystopping(-(roc_auc+ aupr_auc), net)\n",
    "    if earlystopping.flag== True:print(f'early_stopping');break;\n",
    "net= torch.load(f'{params.pt_file}//{params.pt_file_name}')\n",
    "net.eval()\n",
    "with torch.no_grad():\n",
    "    pred= net(valid_xy[:, 0], valid_xy[:, 1])\n",
    "roc_auc, roc_aupr= avg_auc_aupr_cpt(valid_xy, valid_label, pred, (1209, 172))\n",
    "# with open(file= params.memo_file4mkgcn, mode= 'a') as f:\n",
    "    # f.write(f'{params.lr}\\t{params.weight_decay}\\t{roc_auc}\\t{roc_aupr}\\n')\n",
    "print(f'{params.lr}\\t{params.weight_decay}\\t{roc_auc}\\t{roc_aupr}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a35188",
   "metadata": {},
   "outputs": [],
   "source": [
    "net= torch.load(f'{params.pt_file}//{params.pt_file_name}')\n",
    "net.eval();results= []\n",
    "with torch.no_grad():\n",
    "    pred= net(test_xy[:, 0], test_xy[:, 1])\n",
    "results= torch.cat([dl.test_xy.to('cpu'), test_label.view(-1, 1).to('cpu'), pred.view(-1, 1).to('cpu')], dim= 1)\n",
    "print(avg_auc_aupr_cpt(dl.test_xy.to('cpu'), test_label.to('cpu'), pred.to('cpu'), (1209, 172)))\n",
    "# np.savetxt(fname= params.test_result_file, X= results, delimiter= '\\t', encoding= 'utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8e9504",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
